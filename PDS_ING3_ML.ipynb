{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PDS_ING3_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ouhibyann/Sales-forecasting/blob/master/PDS_ING3_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG2Nh5IIWa0T",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyOrJixqoJer",
        "colab_type": "text"
      },
      "source": [
        "# Project : Machine Learning sales forecasting\n",
        "\n",
        "## Aim : \n",
        "\n",
        "\n",
        "*   Predict sales' volume thanks to different Machine Learning algorithms in order to help managers to take actions\n",
        "*   This is the last part of a bigger project which purpose was to monitor a whole shopping center throughout different metrics such as : it's sales, client reviews, product monitoring, ...\n",
        "\n",
        "\n",
        "*The data has been imported from a .csv which has been generated from a MapReduce job from previous steps in the project.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3TMlY0QT97a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as pyoff\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.ensemble import *\n",
        "\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDoJ8c2-ocWB",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 : Data loading, wrangling and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z23qKM_kTzy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the .csv file\n",
        "with open('SalesCLEANED.csv', newline='\\n', mode='r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    row_count = 1\n",
        "    type_product = []\n",
        "    type_sales = []\n",
        "    date = []\n",
        "    price = []\n",
        "    volume = []\n",
        "    for row in csv_reader:\n",
        "        row_count = row_count + 1\n",
        "        type_product.append(row[1])\n",
        "        type_sales.append(row[2])\n",
        "        date.append(row[3])\n",
        "        price.append(float(row[-1]))\n",
        "        volume.append(int(row[-3]))\n",
        "\n",
        "csv_file.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otVrW7HafRx6",
        "colab_type": "code",
        "outputId": "f683d859-007d-4799-856c-dc7c45e2662f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Putting the data in dataframe for better manipulation\n",
        "df = pd.DataFrame(list(zip(type_product, type_sales, date, volume, price)), columns=['type_product', 'type_sales', 'Date', 'volume', 'price'])\n",
        "df['Date'] = pd.to_datetime(df.Date)\n",
        "\n",
        "# Aggregating by month to be more specific for decision making process\n",
        "df['Monthly'] = df['Date'].dt.year.astype('str') + '-' + df['Date'].dt.month.astype('str') + '-01'\n",
        "df['Monthly'] = pd.to_datetime(df['Monthly'])\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_product</th>\n",
              "      <th>type_sales</th>\n",
              "      <th>Date</th>\n",
              "      <th>volume</th>\n",
              "      <th>price</th>\n",
              "      <th>Monthly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fruits</td>\n",
              "      <td>Offline</td>\n",
              "      <td>2012-07-27</td>\n",
              "      <td>6</td>\n",
              "      <td>55.98</td>\n",
              "      <td>2012-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Clothes</td>\n",
              "      <td>Online</td>\n",
              "      <td>2013-09-14</td>\n",
              "      <td>8</td>\n",
              "      <td>874.24</td>\n",
              "      <td>2013-09-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Meat</td>\n",
              "      <td>Offline</td>\n",
              "      <td>2015-05-15</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2015-05-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Clothes</td>\n",
              "      <td>Offline</td>\n",
              "      <td>2017-05-17</td>\n",
              "      <td>5</td>\n",
              "      <td>546.40</td>\n",
              "      <td>2017-05-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beverages</td>\n",
              "      <td>Offline</td>\n",
              "      <td>2016-10-26</td>\n",
              "      <td>9</td>\n",
              "      <td>427.05</td>\n",
              "      <td>2016-10-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  type_product type_sales       Date  volume   price    Monthly\n",
              "0       Fruits    Offline 2012-07-27       6   55.98 2012-07-01\n",
              "1      Clothes     Online 2013-09-14       8  874.24 2013-09-01\n",
              "2         Meat    Offline 2015-05-15       0    0.00 2015-05-01\n",
              "3      Clothes    Offline 2017-05-17       5  546.40 2017-05-01\n",
              "4    Beverages    Offline 2016-10-26       9  427.05 2016-10-01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjWgaGXeSt49",
        "colab_type": "text"
      },
      "source": [
        "As one can observe, there are already a lot of features in the dataset however this study will consider the sales only as a time serie so features other than date and sales - wich is refered as 'volume' in the dataframe - won't be retained.\n",
        "As a result, we've got the following **aggregated dataset** :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQ-mk3Z9cPl",
        "colab_type": "code",
        "outputId": "f7293d07-2814-4dd4-e2dd-9db1dcc65e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_aggregated = df.groupby('Monthly').volume.sum().reset_index()\n",
        "\n",
        "df_aggregated.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Monthly</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>75189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-02-01</td>\n",
              "      <td>68422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-03-01</td>\n",
              "      <td>74926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-01</td>\n",
              "      <td>72102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-05-01</td>\n",
              "      <td>75304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Monthly  volume\n",
              "0 2010-01-01   75189\n",
              "1 2010-02-01   68422\n",
              "2 2010-03-01   74926\n",
              "3 2010-04-01   72102\n",
              "4 2010-05-01   75304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYVnZga6UVrR",
        "colab_type": "code",
        "outputId": "e05870ea-b16a-47c9-c38f-2221bc557d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "plot_data = [go.Scatter(x=df_aggregated['Monthly'], y=df_aggregated['volume'])]\n",
        "plot_layout = go.Layout(title='Ventes mensuelles')\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "pyoff.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"f15f9aab-e9aa-406a-854a-25eb5a0d04d9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"f15f9aab-e9aa-406a-854a-25eb5a0d04d9\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'f15f9aab-e9aa-406a-854a-25eb5a0d04d9',\n",
              "                        [{\"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [75189, 68422, 74926, 72102, 75304, 72838, 75197, 76231, 73055, 73806, 72549, 75068, 76246, 68859, 76355, 73853, 74843, 72383, 75673, 75149, 73620, 75790, 73629, 76471, 73869, 70311, 76015, 73257, 76089, 73380, 76220, 75462, 72690, 75901, 72141, 74354, 76417, 68546, 76048, 72133, 75125, 72899, 75643, 76052, 74163, 75972, 73685, 75559, 76087, 67637, 75765, 73044, 75990, 74231, 75841, 75812, 73284, 76170, 72918, 76032, 74679, 68057, 75422, 72228, 74843, 73277, 75681, 75694, 73420, 75079, 72651, 75578, 75684, 70333, 76230, 73101, 75944, 73462, 76201, 75860, 73185, 75231, 73868, 76264, 75803, 68183, 76256, 73068, 75752, 73676, 69874]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Ventes mensuelles\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f15f9aab-e9aa-406a-854a-25eb5a0d04d9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgA2SVm6Tv2o",
        "colab_type": "text"
      },
      "source": [
        "The figure above demonstrates how the trend in sales is quite homogeneous. Also, febuary is more than often the month where sales are at their lowest. It can be explained as the month after Christimas and new year Eve which results in sales plummeting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbHXF_vEKdH-",
        "colab_type": "text"
      },
      "source": [
        "## Part 2 : features engineering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsXVhiLmUV9N",
        "colab_type": "code",
        "outputId": "1d0de120-0d9c-4788-b111-1fad277aa52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Create new dataframe to model the diff\n",
        "df_diff = df_aggregated.copy()\n",
        "df_diff['prev_sales'] = df_aggregated['volume'].shift(1)\n",
        "df_diff = df_diff.dropna()\n",
        "df_diff['diff'] = (df_diff['volume'] - df_diff['prev_sales'])\n",
        "\n",
        "df_diff.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Monthly</th>\n",
              "      <th>volume</th>\n",
              "      <th>prev_sales</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-02-01</td>\n",
              "      <td>68422</td>\n",
              "      <td>75189.0</td>\n",
              "      <td>-6767.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-03-01</td>\n",
              "      <td>74926</td>\n",
              "      <td>68422.0</td>\n",
              "      <td>6504.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-01</td>\n",
              "      <td>72102</td>\n",
              "      <td>74926.0</td>\n",
              "      <td>-2824.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-05-01</td>\n",
              "      <td>75304</td>\n",
              "      <td>72102.0</td>\n",
              "      <td>3202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2010-06-01</td>\n",
              "      <td>72838</td>\n",
              "      <td>75304.0</td>\n",
              "      <td>-2466.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Monthly  volume  prev_sales    diff\n",
              "1 2010-02-01   68422     75189.0 -6767.0\n",
              "2 2010-03-01   74926     68422.0  6504.0\n",
              "3 2010-04-01   72102     74926.0 -2824.0\n",
              "4 2010-05-01   75304     72102.0  3202.0\n",
              "5 2010-06-01   72838     75304.0 -2466.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUtDRA2tNCSJ",
        "colab_type": "text"
      },
      "source": [
        "Sales and the substract from the previous months.\n",
        "It helps us to understand how sales are varying."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDK4rZcbUV5H",
        "colab_type": "code",
        "outputId": "7b76dee3-30be-475a-b4c5-0420b9393d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Create dataframe for transformation from time series to supervised dataset\n",
        "# We use previous monthly sales data as features so basically 12 months so 12 features\n",
        "df_supervised = df_diff.drop(['prev_sales'], axis=1)\n",
        "for i in range(1, 13):\n",
        "    field_name = 'lag' + str(i)\n",
        "    df_supervised[field_name] = df_supervised['diff'].shift(i)\n",
        "\n",
        "df_supervised = df_supervised.dropna().reset_index(drop=True)\n",
        "\n",
        "df_supervised.head(-10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Monthly</th>\n",
              "      <th>volume</th>\n",
              "      <th>diff</th>\n",
              "      <th>lag1</th>\n",
              "      <th>lag2</th>\n",
              "      <th>lag3</th>\n",
              "      <th>lag4</th>\n",
              "      <th>lag5</th>\n",
              "      <th>lag6</th>\n",
              "      <th>lag7</th>\n",
              "      <th>lag8</th>\n",
              "      <th>lag9</th>\n",
              "      <th>lag10</th>\n",
              "      <th>lag11</th>\n",
              "      <th>lag12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>68859</td>\n",
              "      <td>-7387.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>2519.0</td>\n",
              "      <td>-1257.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>-3176.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>2359.0</td>\n",
              "      <td>-2466.0</td>\n",
              "      <td>3202.0</td>\n",
              "      <td>-2824.0</td>\n",
              "      <td>6504.0</td>\n",
              "      <td>-6767.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-03-01</td>\n",
              "      <td>76355</td>\n",
              "      <td>7496.0</td>\n",
              "      <td>-7387.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>2519.0</td>\n",
              "      <td>-1257.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>-3176.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>2359.0</td>\n",
              "      <td>-2466.0</td>\n",
              "      <td>3202.0</td>\n",
              "      <td>-2824.0</td>\n",
              "      <td>6504.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-04-01</td>\n",
              "      <td>73853</td>\n",
              "      <td>-2502.0</td>\n",
              "      <td>7496.0</td>\n",
              "      <td>-7387.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>2519.0</td>\n",
              "      <td>-1257.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>-3176.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>2359.0</td>\n",
              "      <td>-2466.0</td>\n",
              "      <td>3202.0</td>\n",
              "      <td>-2824.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-05-01</td>\n",
              "      <td>74843</td>\n",
              "      <td>990.0</td>\n",
              "      <td>-2502.0</td>\n",
              "      <td>7496.0</td>\n",
              "      <td>-7387.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>2519.0</td>\n",
              "      <td>-1257.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>-3176.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>2359.0</td>\n",
              "      <td>-2466.0</td>\n",
              "      <td>3202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-06-01</td>\n",
              "      <td>72383</td>\n",
              "      <td>-2460.0</td>\n",
              "      <td>990.0</td>\n",
              "      <td>-2502.0</td>\n",
              "      <td>7496.0</td>\n",
              "      <td>-7387.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>2519.0</td>\n",
              "      <td>-1257.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>-3176.0</td>\n",
              "      <td>1034.0</td>\n",
              "      <td>2359.0</td>\n",
              "      <td>-2466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>2016-05-01</td>\n",
              "      <td>75944</td>\n",
              "      <td>2843.0</td>\n",
              "      <td>-3129.0</td>\n",
              "      <td>5897.0</td>\n",
              "      <td>-5351.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>2927.0</td>\n",
              "      <td>-2428.0</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>-2274.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2404.0</td>\n",
              "      <td>-1566.0</td>\n",
              "      <td>2615.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>2016-06-01</td>\n",
              "      <td>73462</td>\n",
              "      <td>-2482.0</td>\n",
              "      <td>2843.0</td>\n",
              "      <td>-3129.0</td>\n",
              "      <td>5897.0</td>\n",
              "      <td>-5351.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>2927.0</td>\n",
              "      <td>-2428.0</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>-2274.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2404.0</td>\n",
              "      <td>-1566.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>76201</td>\n",
              "      <td>2739.0</td>\n",
              "      <td>-2482.0</td>\n",
              "      <td>2843.0</td>\n",
              "      <td>-3129.0</td>\n",
              "      <td>5897.0</td>\n",
              "      <td>-5351.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>2927.0</td>\n",
              "      <td>-2428.0</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>-2274.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2404.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>2016-08-01</td>\n",
              "      <td>75860</td>\n",
              "      <td>-341.0</td>\n",
              "      <td>2739.0</td>\n",
              "      <td>-2482.0</td>\n",
              "      <td>2843.0</td>\n",
              "      <td>-3129.0</td>\n",
              "      <td>5897.0</td>\n",
              "      <td>-5351.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>2927.0</td>\n",
              "      <td>-2428.0</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>-2274.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2016-09-01</td>\n",
              "      <td>73185</td>\n",
              "      <td>-2675.0</td>\n",
              "      <td>-341.0</td>\n",
              "      <td>2739.0</td>\n",
              "      <td>-2482.0</td>\n",
              "      <td>2843.0</td>\n",
              "      <td>-3129.0</td>\n",
              "      <td>5897.0</td>\n",
              "      <td>-5351.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>2927.0</td>\n",
              "      <td>-2428.0</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>-2274.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Monthly  volume    diff    lag1  ...    lag9   lag10   lag11   lag12\n",
              "0  2011-02-01   68859 -7387.0  1178.0  ...  3202.0 -2824.0  6504.0 -6767.0\n",
              "1  2011-03-01   76355  7496.0 -7387.0  ... -2466.0  3202.0 -2824.0  6504.0\n",
              "2  2011-04-01   73853 -2502.0  7496.0  ...  2359.0 -2466.0  3202.0 -2824.0\n",
              "3  2011-05-01   74843   990.0 -2502.0  ...  1034.0  2359.0 -2466.0  3202.0\n",
              "4  2011-06-01   72383 -2460.0   990.0  ... -3176.0  1034.0  2359.0 -2466.0\n",
              "..        ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
              "63 2016-05-01   75944  2843.0 -3129.0  ...    13.0  2404.0 -1566.0  2615.0\n",
              "64 2016-06-01   73462 -2482.0  2843.0  ... -2274.0    13.0  2404.0 -1566.0\n",
              "65 2016-07-01   76201  2739.0 -2482.0  ...  1659.0 -2274.0    13.0  2404.0\n",
              "66 2016-08-01   75860  -341.0  2739.0  ... -2428.0  1659.0 -2274.0    13.0\n",
              "67 2016-09-01   73185 -2675.0  -341.0  ...  2927.0 -2428.0  1659.0 -2274.0\n",
              "\n",
              "[68 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkEM4EOpUy4c",
        "colab_type": "text"
      },
      "source": [
        "Using data shifting in order to generate features.\n",
        "We use previous monthly sales data as features on a time frame of 12 months - so 12 features.\n",
        "One could argue the 'diff' column should not be present as a feature but it might be removed later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK7jjdR2UdG2",
        "colab_type": "code",
        "outputId": "3aa66a98-de78-4631-cc3a-78b322659999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Adjusted R-squared \n",
        "model = smf.ols(formula='diff ~ lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7 + lag8 + lag9 +lag10 + lag11 + lag12', data=df_supervised)\n",
        "model_fit = model.fit()\n",
        "\n",
        "print(\"R² = \", model_fit.rsquared_adj)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R² =  0.8843458157025764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0xutDBUB3rC",
        "colab_type": "code",
        "outputId": "e8d69bfa-f7c8-4b06-9e1b-9313ecb53f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "# Correlation matrix\n",
        "df_supervised.corr()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>volume</th>\n",
              "      <th>diff</th>\n",
              "      <th>lag1</th>\n",
              "      <th>lag2</th>\n",
              "      <th>lag3</th>\n",
              "      <th>lag4</th>\n",
              "      <th>lag5</th>\n",
              "      <th>lag6</th>\n",
              "      <th>lag7</th>\n",
              "      <th>lag8</th>\n",
              "      <th>lag9</th>\n",
              "      <th>lag10</th>\n",
              "      <th>lag11</th>\n",
              "      <th>lag12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>volume</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.856449</td>\n",
              "      <td>-0.348826</td>\n",
              "      <td>0.072238</td>\n",
              "      <td>0.093920</td>\n",
              "      <td>-0.245913</td>\n",
              "      <td>0.438726</td>\n",
              "      <td>-0.378651</td>\n",
              "      <td>0.153750</td>\n",
              "      <td>-0.026834</td>\n",
              "      <td>-0.136151</td>\n",
              "      <td>0.374142</td>\n",
              "      <td>-0.763630</td>\n",
              "      <td>0.764504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diff</th>\n",
              "      <td>0.856449</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.703378</td>\n",
              "      <td>0.252804</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>-0.189596</td>\n",
              "      <td>0.381141</td>\n",
              "      <td>-0.460664</td>\n",
              "      <td>0.311883</td>\n",
              "      <td>-0.112213</td>\n",
              "      <td>-0.065270</td>\n",
              "      <td>0.298778</td>\n",
              "      <td>-0.670813</td>\n",
              "      <td>0.909035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag1</th>\n",
              "      <td>-0.348826</td>\n",
              "      <td>-0.703378</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.711428</td>\n",
              "      <td>0.263011</td>\n",
              "      <td>-0.006384</td>\n",
              "      <td>-0.169979</td>\n",
              "      <td>0.367444</td>\n",
              "      <td>-0.461064</td>\n",
              "      <td>0.319611</td>\n",
              "      <td>-0.113625</td>\n",
              "      <td>-0.061349</td>\n",
              "      <td>0.293024</td>\n",
              "      <td>-0.668868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag2</th>\n",
              "      <td>0.072238</td>\n",
              "      <td>0.252804</td>\n",
              "      <td>-0.711428</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.710376</td>\n",
              "      <td>0.259370</td>\n",
              "      <td>0.002308</td>\n",
              "      <td>-0.188124</td>\n",
              "      <td>0.370954</td>\n",
              "      <td>-0.461777</td>\n",
              "      <td>0.323059</td>\n",
              "      <td>-0.116142</td>\n",
              "      <td>-0.049826</td>\n",
              "      <td>0.268841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag3</th>\n",
              "      <td>0.093920</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>0.263011</td>\n",
              "      <td>-0.710376</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.708270</td>\n",
              "      <td>0.249980</td>\n",
              "      <td>0.021462</td>\n",
              "      <td>-0.189777</td>\n",
              "      <td>0.368596</td>\n",
              "      <td>-0.461340</td>\n",
              "      <td>0.321403</td>\n",
              "      <td>-0.115362</td>\n",
              "      <td>-0.039435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag4</th>\n",
              "      <td>-0.245913</td>\n",
              "      <td>-0.189596</td>\n",
              "      <td>-0.006384</td>\n",
              "      <td>0.259370</td>\n",
              "      <td>-0.708270</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.708084</td>\n",
              "      <td>0.234748</td>\n",
              "      <td>0.021660</td>\n",
              "      <td>-0.184715</td>\n",
              "      <td>0.366604</td>\n",
              "      <td>-0.458060</td>\n",
              "      <td>0.313278</td>\n",
              "      <td>-0.119332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag5</th>\n",
              "      <td>0.438726</td>\n",
              "      <td>0.381141</td>\n",
              "      <td>-0.169979</td>\n",
              "      <td>0.002308</td>\n",
              "      <td>0.249980</td>\n",
              "      <td>-0.708084</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.688925</td>\n",
              "      <td>0.237096</td>\n",
              "      <td>0.010242</td>\n",
              "      <td>-0.187900</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>-0.460845</td>\n",
              "      <td>0.339208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag6</th>\n",
              "      <td>-0.378651</td>\n",
              "      <td>-0.460664</td>\n",
              "      <td>0.367444</td>\n",
              "      <td>-0.188124</td>\n",
              "      <td>0.021462</td>\n",
              "      <td>0.234748</td>\n",
              "      <td>-0.688925</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.708738</td>\n",
              "      <td>0.260615</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>-0.179911</td>\n",
              "      <td>0.358260</td>\n",
              "      <td>-0.474372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag7</th>\n",
              "      <td>0.153750</td>\n",
              "      <td>0.311883</td>\n",
              "      <td>-0.461064</td>\n",
              "      <td>0.370954</td>\n",
              "      <td>-0.189777</td>\n",
              "      <td>0.021660</td>\n",
              "      <td>0.237096</td>\n",
              "      <td>-0.708738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.711536</td>\n",
              "      <td>0.265968</td>\n",
              "      <td>-0.002930</td>\n",
              "      <td>-0.161827</td>\n",
              "      <td>0.332639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag8</th>\n",
              "      <td>-0.026834</td>\n",
              "      <td>-0.112213</td>\n",
              "      <td>0.319611</td>\n",
              "      <td>-0.461777</td>\n",
              "      <td>0.368596</td>\n",
              "      <td>-0.184715</td>\n",
              "      <td>0.010242</td>\n",
              "      <td>0.260615</td>\n",
              "      <td>-0.711536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.713163</td>\n",
              "      <td>0.267663</td>\n",
              "      <td>-0.012881</td>\n",
              "      <td>-0.139857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag9</th>\n",
              "      <td>-0.136151</td>\n",
              "      <td>-0.065270</td>\n",
              "      <td>-0.113625</td>\n",
              "      <td>0.323059</td>\n",
              "      <td>-0.461340</td>\n",
              "      <td>0.366604</td>\n",
              "      <td>-0.187900</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.265968</td>\n",
              "      <td>-0.713163</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.715172</td>\n",
              "      <td>0.279356</td>\n",
              "      <td>-0.035220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag10</th>\n",
              "      <td>0.374142</td>\n",
              "      <td>0.298778</td>\n",
              "      <td>-0.061349</td>\n",
              "      <td>-0.116142</td>\n",
              "      <td>0.321403</td>\n",
              "      <td>-0.458060</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>-0.179911</td>\n",
              "      <td>-0.002930</td>\n",
              "      <td>0.267663</td>\n",
              "      <td>-0.715172</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.714334</td>\n",
              "      <td>0.292843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag11</th>\n",
              "      <td>-0.763630</td>\n",
              "      <td>-0.670813</td>\n",
              "      <td>0.293024</td>\n",
              "      <td>-0.049826</td>\n",
              "      <td>-0.115362</td>\n",
              "      <td>0.313278</td>\n",
              "      <td>-0.460845</td>\n",
              "      <td>0.358260</td>\n",
              "      <td>-0.161827</td>\n",
              "      <td>-0.012881</td>\n",
              "      <td>0.279356</td>\n",
              "      <td>-0.714334</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.730675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag12</th>\n",
              "      <td>0.764504</td>\n",
              "      <td>0.909035</td>\n",
              "      <td>-0.668868</td>\n",
              "      <td>0.268841</td>\n",
              "      <td>-0.039435</td>\n",
              "      <td>-0.119332</td>\n",
              "      <td>0.339208</td>\n",
              "      <td>-0.474372</td>\n",
              "      <td>0.332639</td>\n",
              "      <td>-0.139857</td>\n",
              "      <td>-0.035220</td>\n",
              "      <td>0.292843</td>\n",
              "      <td>-0.730675</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          volume      diff      lag1  ...     lag10     lag11     lag12\n",
              "volume  1.000000  0.856449 -0.348826  ...  0.374142 -0.763630  0.764504\n",
              "diff    0.856449  1.000000 -0.703378  ...  0.298778 -0.670813  0.909035\n",
              "lag1   -0.348826 -0.703378  1.000000  ... -0.061349  0.293024 -0.668868\n",
              "lag2    0.072238  0.252804 -0.711428  ... -0.116142 -0.049826  0.268841\n",
              "lag3    0.093920  0.004196  0.263011  ...  0.321403 -0.115362 -0.039435\n",
              "lag4   -0.245913 -0.189596 -0.006384  ... -0.458060  0.313278 -0.119332\n",
              "lag5    0.438726  0.381141 -0.169979  ...  0.368201 -0.460845  0.339208\n",
              "lag6   -0.378651 -0.460664  0.367444  ... -0.179911  0.358260 -0.474372\n",
              "lag7    0.153750  0.311883 -0.461064  ... -0.002930 -0.161827  0.332639\n",
              "lag8   -0.026834 -0.112213  0.319611  ...  0.267663 -0.012881 -0.139857\n",
              "lag9   -0.136151 -0.065270 -0.113625  ... -0.715172  0.279356 -0.035220\n",
              "lag10   0.374142  0.298778 -0.061349  ...  1.000000 -0.714334  0.292843\n",
              "lag11  -0.763630 -0.670813  0.293024  ... -0.714334  1.000000 -0.730675\n",
              "lag12   0.764504  0.909035 -0.668868  ...  0.292843 -0.730675  1.000000\n",
              "\n",
              "[14 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqvKQQNmVDmt",
        "colab_type": "text"
      },
      "source": [
        "R squared and correlations help to confirm our features are useful and not repetitive.\n",
        "Thanks to regression of 'diff' on 'lag1' to 'lag12', we know the differences can be explained through those features.\n",
        "The correlation matrix assures there are no strong correlation - the next cell will display the strongest correlations and as we will see, it is at most 0.9 - not very strong in our context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Do4aEZN4Lm",
        "colab_type": "code",
        "outputId": "87363c59-1b3a-4b7e-c2e6-1c631489607c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# First 15 correlations\n",
        "c = df_supervised.corr()\n",
        "s = c.unstack()\n",
        "so = s.sort_values(kind=\"quicksort\")\n",
        "\n",
        "print(so[-15:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "diff    lag12     0.909035\n",
            "volume  volume    1.000000\n",
            "lag10   lag10     1.000000\n",
            "lag9    lag9      1.000000\n",
            "lag8    lag8      1.000000\n",
            "lag7    lag7      1.000000\n",
            "lag6    lag6      1.000000\n",
            "lag5    lag5      1.000000\n",
            "lag4    lag4      1.000000\n",
            "lag3    lag3      1.000000\n",
            "lag2    lag2      1.000000\n",
            "lag1    lag1      1.000000\n",
            "diff    diff      1.000000\n",
            "lag11   lag11     1.000000\n",
            "lag12   lag12     1.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8g2Ggo3K2xJ",
        "colab_type": "text"
      },
      "source": [
        "Here are the correlations, obvisously the first 13 correlations are from the diagonal of the matrix - thus all equal to 1.\n",
        "The next one is a feature correlated to 'diff', but as mentionned earlier the 'diff' column will be droped later on.\n",
        "\n",
        "Next, let's split the dataset in training and testing - 6 years of training 1 year of testing.\n",
        "Before all else, we are going to reshape the data by substracting the mean and dividing by the standart deviation, then reshape between [-1,1] for the activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN7xtZvpUesZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's split train and test sets\n",
        "df_model = df_supervised.drop(['volume','Monthly'],axis=1)\n",
        "\n",
        "train_set, test_set = df_model[0:-13].values, df_model[-13:].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFkXMs5uFcOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling each features [-1;1]\n",
        "# Thus will limit side effects in the neural net through the activation function\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler = scaler.fit(train_set)\n",
        "\n",
        "# Reshape training set\n",
        "# Normalizing \n",
        "train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\n",
        "train_set_scaled = scaler.transform(train_set)\n",
        "\n",
        "# Reshape training set\n",
        "# Normalizing \n",
        "test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\n",
        "test_set_scaled = scaler.transform(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7OlD9ZhG5HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCCHrYTuK3Rb",
        "colab_type": "text"
      },
      "source": [
        "## Part 3 : RNN training and testing\n",
        "\n",
        "Recurrent Neural Network is one of the most used model - with ARIMA model - for time series. Let's see how it can be used in our context and if the results are satisfying."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFhW_ccG0Zbk",
        "colab_type": "text"
      },
      "source": [
        "### The first model tried\n",
        "\n",
        "In this part I'm going to present the results from the 'first' model - before tuning parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULS6tDO51huw",
        "colab_type": "code",
        "outputId": "d6850c85-e3bb-4e71-cd5f-8fb6ecd5c831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Intializing the neural net\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM to the neural net. \n",
        "# If needed, we will do some parameters tuning by changing activation, units, ...\n",
        "model.add(LSTM(units = 4, activation='tanh', recurrent_activation='sigmoid', use_bias=True, batch_input_shape=(1, X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "# If overfitting happens, we can use dropout\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# Stochastic Gradient Descent for the moment event though it might not be the best optimizer and batch_size of 1.\n",
        "model.compile(loss='mean_squared_error', optimizer='SGD')\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1, shuffle=False) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.1924\n",
            "Epoch 2/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.1655\n",
            "Epoch 3/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.1437\n",
            "Epoch 4/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.1258\n",
            "Epoch 5/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.1109\n",
            "Epoch 6/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0985\n",
            "Epoch 7/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0881\n",
            "Epoch 8/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0793\n",
            "Epoch 9/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0721\n",
            "Epoch 10/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0660\n",
            "Epoch 11/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0609\n",
            "Epoch 12/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0566\n",
            "Epoch 13/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0530\n",
            "Epoch 14/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0500\n",
            "Epoch 15/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0474\n",
            "Epoch 16/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0452\n",
            "Epoch 17/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 18/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0416\n",
            "Epoch 19/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0401\n",
            "Epoch 20/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0387\n",
            "Epoch 21/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0375\n",
            "Epoch 22/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0364\n",
            "Epoch 23/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0354\n",
            "Epoch 24/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0344\n",
            "Epoch 25/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0336\n",
            "Epoch 26/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0327\n",
            "Epoch 27/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0319\n",
            "Epoch 28/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0312\n",
            "Epoch 29/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0305\n",
            "Epoch 30/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0298\n",
            "Epoch 31/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0292\n",
            "Epoch 32/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0286\n",
            "Epoch 33/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0280\n",
            "Epoch 34/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0275\n",
            "Epoch 35/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0270\n",
            "Epoch 36/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0265\n",
            "Epoch 37/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0260\n",
            "Epoch 38/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0255\n",
            "Epoch 39/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0251\n",
            "Epoch 40/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0247\n",
            "Epoch 41/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0243\n",
            "Epoch 42/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0240\n",
            "Epoch 43/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0236\n",
            "Epoch 44/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0233\n",
            "Epoch 45/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0229\n",
            "Epoch 46/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0226\n",
            "Epoch 47/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0223\n",
            "Epoch 48/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0221\n",
            "Epoch 49/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0218\n",
            "Epoch 50/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0216\n",
            "Epoch 51/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0213\n",
            "Epoch 52/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0211\n",
            "Epoch 53/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0209\n",
            "Epoch 54/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0207\n",
            "Epoch 55/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0205\n",
            "Epoch 56/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0203\n",
            "Epoch 57/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0201\n",
            "Epoch 58/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0199\n",
            "Epoch 59/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0198\n",
            "Epoch 60/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0196\n",
            "Epoch 61/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0194\n",
            "Epoch 62/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0193\n",
            "Epoch 63/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0192\n",
            "Epoch 64/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0190\n",
            "Epoch 65/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0189\n",
            "Epoch 66/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0188\n",
            "Epoch 67/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0187\n",
            "Epoch 68/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0186\n",
            "Epoch 69/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "Epoch 70/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0183\n",
            "Epoch 71/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0182\n",
            "Epoch 72/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0181\n",
            "Epoch 73/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 74/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "Epoch 75/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0179\n",
            "Epoch 76/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 77/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 78/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "Epoch 79/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0175\n",
            "Epoch 80/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0175\n",
            "Epoch 81/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0174\n",
            "Epoch 82/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0173\n",
            "Epoch 83/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "Epoch 84/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "Epoch 85/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0171\n",
            "Epoch 86/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0171\n",
            "Epoch 87/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0170\n",
            "Epoch 88/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0169\n",
            "Epoch 89/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0169\n",
            "Epoch 90/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0168\n",
            "Epoch 91/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0167\n",
            "Epoch 92/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0167\n",
            "Epoch 93/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0166\n",
            "Epoch 94/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0166\n",
            "Epoch 95/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0165\n",
            "Epoch 96/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0165\n",
            "Epoch 97/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.0164\n",
            "Epoch 98/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0164\n",
            "Epoch 99/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0163\n",
            "Epoch 100/100\n",
            "65/65 [==============================] - 0s 1ms/step - loss: 0.0163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8a6b187ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvmTWcoJ1hxL",
        "colab_type": "code",
        "outputId": "1b70c7c3-d9f4-43bb-b8d6-284981cb7b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# Let's test the model\n",
        "y_pred = model.predict(X_test,batch_size=1)\n",
        "\n",
        "y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
        "\n",
        "# Rebuilding test set\n",
        "pred_test_set = []\n",
        "for index in range(0,len(y_pred)):\n",
        "    print(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
        "    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
        "\n",
        "# Reshape pred_test_set\n",
        "pred_test_set = np.array(pred_test_set)\n",
        "pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
        "pred_test_set_inverted = scaler.inverse_transform(pred_test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.3105329  -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102\n",
            "   0.03221136  0.37254192 -0.27349499  0.2195681  -0.25491615  0.02099168\n",
            "   0.30944625]]\n",
            "[[-0.00686472  0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811\n",
            "  -0.62613102  0.03221136  0.37254192 -0.27349499  0.2195681  -0.25491615\n",
            "   0.02099168]]\n",
            "[[-0.19671489 -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491\n",
            "   0.73084811 -0.62613102  0.03221136  0.37254192 -0.27349499  0.2195681\n",
            "  -0.25491615]]\n",
            "[[ 0.31484362 -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801\n",
            "  -0.35806491  0.73084811 -0.62613102  0.03221136  0.37254192 -0.27349499\n",
            "   0.2195681 ]]\n",
            "[[-0.29209313  0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965\n",
            "   0.36240801 -0.35806491  0.73084811 -0.62613102  0.03221136  0.37254192\n",
            "  -0.27349499]]\n",
            "[[ 0.25164807 -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126\n",
            "  -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102  0.03221136\n",
            "   0.37254192]]\n",
            "[[ 0.02617502  0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553\n",
            "   0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102\n",
            "   0.03221136]]\n",
            "[[-0.5820272  -0.03619254  0.30848112 -0.14501146  0.26625648 -0.30329352\n",
            "  -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811\n",
            "  -0.62613102]]\n",
            "[[ 0.83921027 -0.89986729 -0.03619254  0.30848112 -0.14501146  0.26625648\n",
            "  -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491\n",
            "   0.73084811]]\n",
            "[[-0.44869119  0.9933647  -0.89986729 -0.03619254  0.30848112 -0.14501146\n",
            "   0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801\n",
            "  -0.35806491]]\n",
            "[[ 0.27070418 -0.36518277  0.9933647  -0.89986729 -0.03619254  0.30848112\n",
            "  -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965\n",
            "   0.36240801]]\n",
            "[[-0.25075424  0.34322596 -0.36518277  0.9933647  -0.89986729 -0.03619254\n",
            "   0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126\n",
            "  -0.28000965]]\n",
            "[[ 0.37661409 -0.23102907  0.34322596 -0.36518277  0.9933647  -0.89986729\n",
            "  -0.03619254  0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553\n",
            "   0.34986126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CK_0hBx5UiH",
        "colab_type": "code",
        "outputId": "ace37c6b-1e7f-449e-83e5-7b0b763411d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Creating a dataframe containing the predictions\n",
        "result_list = []\n",
        "sales_dates = list(df_aggregated[-13:].Monthly)\n",
        "act_sales = list(df_aggregated[-13:].volume)\n",
        "for index in range(0,len(pred_test_set_inverted)):\n",
        "    result_dict = {}\n",
        "    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n",
        "    result_dict['Monthly'] = sales_dates[index]\n",
        "    result_list.append(result_dict)\n",
        "df_result = pd.DataFrame(result_list)\n",
        "df_result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_value</th>\n",
              "      <th>Monthly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78614</td>\n",
              "      <td>2016-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>75642</td>\n",
              "      <td>2016-08-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71393</td>\n",
              "      <td>2016-09-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>77679</td>\n",
              "      <td>2016-10-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71285</td>\n",
              "      <td>2016-11-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pred_value    Monthly\n",
              "0       78614 2016-07-01\n",
              "1       75642 2016-08-01\n",
              "2       71393 2016-09-01\n",
              "3       77679 2016-10-01\n",
              "4       71285 2016-11-01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ZwIF2q1hz8",
        "colab_type": "code",
        "outputId": "9c24638f-9f09-422e-9fcd-e4f6fb6b5326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "# We merge the previous sales and predicted sales for vizualisation\n",
        "df_sales_pred = pd.merge(df_aggregated,df_result,on='Monthly',how='left')\n",
        "\n",
        "# Plot actual and predicted\n",
        "plot_data = [\n",
        "    go.Scatter(\n",
        "        x=df_sales_pred['Monthly'],\n",
        "        y=df_sales_pred['volume'],\n",
        "        name='actual'\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        x=df_sales_pred['Monthly'],\n",
        "        y=df_sales_pred['pred_value'],\n",
        "        name='predicted'\n",
        "    )\n",
        "    \n",
        "]\n",
        "plot_layout = go.Layout(\n",
        "        title='Sales Prediction'\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "pyoff.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"86391ede-0294-4337-9ca6-35f7b383c6c6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"86391ede-0294-4337-9ca6-35f7b383c6c6\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '86391ede-0294-4337-9ca6-35f7b383c6c6',\n",
              "                        [{\"name\": \"actual\", \"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [75189, 68422, 74926, 72102, 75304, 72838, 75197, 76231, 73055, 73806, 72549, 75068, 76246, 68859, 76355, 73853, 74843, 72383, 75673, 75149, 73620, 75790, 73629, 76471, 73869, 70311, 76015, 73257, 76089, 73380, 76220, 75462, 72690, 75901, 72141, 74354, 76417, 68546, 76048, 72133, 75125, 72899, 75643, 76052, 74163, 75972, 73685, 75559, 76087, 67637, 75765, 73044, 75990, 74231, 75841, 75812, 73284, 76170, 72918, 76032, 74679, 68057, 75422, 72228, 74843, 73277, 75681, 75694, 73420, 75079, 72651, 75578, 75684, 70333, 76230, 73101, 75944, 73462, 76201, 75860, 73185, 75231, 73868, 76264, 75803, 68183, 76256, 73068, 75752, 73676, 69874]}, {\"name\": \"predicted\", \"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 78614.0, 75642.0, 71393.0, 77679.0, 71285.0, 78188.0, 75858.0, 63197.0, 83051.0, 69187.0, 77834.0, 71436.0, 72834.0]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Sales Prediction\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('86391ede-0294-4337-9ca6-35f7b383c6c6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcrKJM3k102D",
        "colab_type": "text"
      },
      "source": [
        "### The optimal model for RNN \n",
        "\n",
        "In this subpart, you will observe the model which gave the best results. As I said earlier, I only changed the batch_size to 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUzv379qG58m",
        "colab_type": "code",
        "outputId": "fb47cceb-8419-481b-9e9a-5537ee4589dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Creating the neural net\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM to the neural net. \n",
        "# If needed, we will do some parameters tuning by changing activation, units, ...\n",
        "model.add(LSTM(units = 4, activation='tanh', recurrent_activation='sigmoid', use_bias=True, batch_input_shape=(1, X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "# If overfitting happens, we can use dropout\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Stochastic Gradient Descent for the moment event though it might not be the best optimizer and batch_size of 1.\n",
        "model.compile(loss='mean_squared_error', optimizer='SGD')\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, shuffle=False) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.1975\n",
            "Epoch 2/100\n",
            "65/65 [==============================] - 0s 128us/step - loss: 0.1972\n",
            "Epoch 3/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.1970\n",
            "Epoch 4/100\n",
            "65/65 [==============================] - 0s 104us/step - loss: 0.1969\n",
            "Epoch 5/100\n",
            "65/65 [==============================] - 0s 114us/step - loss: 0.1968\n",
            "Epoch 6/100\n",
            "65/65 [==============================] - 0s 125us/step - loss: 0.1968\n",
            "Epoch 7/100\n",
            "65/65 [==============================] - 0s 122us/step - loss: 0.1968\n",
            "Epoch 8/100\n",
            "65/65 [==============================] - 0s 153us/step - loss: 0.1969\n",
            "Epoch 9/100\n",
            "65/65 [==============================] - 0s 158us/step - loss: 0.1970\n",
            "Epoch 10/100\n",
            "65/65 [==============================] - 0s 113us/step - loss: 0.1971\n",
            "Epoch 11/100\n",
            "65/65 [==============================] - 0s 137us/step - loss: 0.1973\n",
            "Epoch 12/100\n",
            "65/65 [==============================] - 0s 99us/step - loss: 0.1974\n",
            "Epoch 13/100\n",
            "65/65 [==============================] - 0s 98us/step - loss: 0.1976\n",
            "Epoch 14/100\n",
            "65/65 [==============================] - 0s 98us/step - loss: 0.1977\n",
            "Epoch 15/100\n",
            "65/65 [==============================] - 0s 122us/step - loss: 0.1979\n",
            "Epoch 16/100\n",
            "65/65 [==============================] - 0s 131us/step - loss: 0.1981\n",
            "Epoch 17/100\n",
            "65/65 [==============================] - 0s 157us/step - loss: 0.1982\n",
            "Epoch 18/100\n",
            "65/65 [==============================] - 0s 165us/step - loss: 0.1984\n",
            "Epoch 19/100\n",
            "65/65 [==============================] - 0s 233us/step - loss: 0.1985\n",
            "Epoch 20/100\n",
            "65/65 [==============================] - 0s 174us/step - loss: 0.1987\n",
            "Epoch 21/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.1988\n",
            "Epoch 22/100\n",
            "65/65 [==============================] - 0s 153us/step - loss: 0.1990\n",
            "Epoch 23/100\n",
            "65/65 [==============================] - 0s 171us/step - loss: 0.1991\n",
            "Epoch 24/100\n",
            "65/65 [==============================] - 0s 145us/step - loss: 0.1992\n",
            "Epoch 25/100\n",
            "65/65 [==============================] - 0s 132us/step - loss: 0.1993\n",
            "Epoch 26/100\n",
            "65/65 [==============================] - 0s 165us/step - loss: 0.1994\n",
            "Epoch 27/100\n",
            "65/65 [==============================] - 0s 172us/step - loss: 0.1995\n",
            "Epoch 28/100\n",
            "65/65 [==============================] - 0s 139us/step - loss: 0.1996\n",
            "Epoch 29/100\n",
            "65/65 [==============================] - 0s 134us/step - loss: 0.1997\n",
            "Epoch 30/100\n",
            "65/65 [==============================] - 0s 159us/step - loss: 0.1998\n",
            "Epoch 31/100\n",
            "65/65 [==============================] - 0s 168us/step - loss: 0.1998\n",
            "Epoch 32/100\n",
            "65/65 [==============================] - 0s 144us/step - loss: 0.1999\n",
            "Epoch 33/100\n",
            "65/65 [==============================] - 0s 134us/step - loss: 0.1999\n",
            "Epoch 34/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.2000\n",
            "Epoch 35/100\n",
            "65/65 [==============================] - 0s 143us/step - loss: 0.2000\n",
            "Epoch 36/100\n",
            "65/65 [==============================] - 0s 149us/step - loss: 0.2001\n",
            "Epoch 37/100\n",
            "65/65 [==============================] - 0s 132us/step - loss: 0.2001\n",
            "Epoch 38/100\n",
            "65/65 [==============================] - 0s 119us/step - loss: 0.2001\n",
            "Epoch 39/100\n",
            "65/65 [==============================] - 0s 106us/step - loss: 0.2002\n",
            "Epoch 40/100\n",
            "65/65 [==============================] - 0s 114us/step - loss: 0.2002\n",
            "Epoch 41/100\n",
            "65/65 [==============================] - 0s 134us/step - loss: 0.2002\n",
            "Epoch 42/100\n",
            "65/65 [==============================] - 0s 119us/step - loss: 0.2002\n",
            "Epoch 43/100\n",
            "65/65 [==============================] - 0s 122us/step - loss: 0.2002\n",
            "Epoch 44/100\n",
            "65/65 [==============================] - 0s 117us/step - loss: 0.2002\n",
            "Epoch 45/100\n",
            "65/65 [==============================] - 0s 113us/step - loss: 0.2002\n",
            "Epoch 46/100\n",
            "65/65 [==============================] - 0s 150us/step - loss: 0.2002\n",
            "Epoch 47/100\n",
            "65/65 [==============================] - 0s 177us/step - loss: 0.2002\n",
            "Epoch 48/100\n",
            "65/65 [==============================] - 0s 147us/step - loss: 0.2002\n",
            "Epoch 49/100\n",
            "65/65 [==============================] - 0s 149us/step - loss: 0.2002\n",
            "Epoch 50/100\n",
            "65/65 [==============================] - 0s 148us/step - loss: 0.2002\n",
            "Epoch 51/100\n",
            "65/65 [==============================] - 0s 170us/step - loss: 0.2002\n",
            "Epoch 52/100\n",
            "65/65 [==============================] - 0s 142us/step - loss: 0.2002\n",
            "Epoch 53/100\n",
            "65/65 [==============================] - 0s 114us/step - loss: 0.2002\n",
            "Epoch 54/100\n",
            "65/65 [==============================] - 0s 124us/step - loss: 0.2002\n",
            "Epoch 55/100\n",
            "65/65 [==============================] - 0s 128us/step - loss: 0.2001\n",
            "Epoch 56/100\n",
            "65/65 [==============================] - 0s 117us/step - loss: 0.2001\n",
            "Epoch 57/100\n",
            "65/65 [==============================] - 0s 109us/step - loss: 0.2001\n",
            "Epoch 58/100\n",
            "65/65 [==============================] - 0s 105us/step - loss: 0.2001\n",
            "Epoch 59/100\n",
            "65/65 [==============================] - 0s 143us/step - loss: 0.2001\n",
            "Epoch 60/100\n",
            "65/65 [==============================] - 0s 153us/step - loss: 0.2000\n",
            "Epoch 61/100\n",
            "65/65 [==============================] - 0s 101us/step - loss: 0.2000\n",
            "Epoch 62/100\n",
            "65/65 [==============================] - 0s 107us/step - loss: 0.2000\n",
            "Epoch 63/100\n",
            "65/65 [==============================] - 0s 113us/step - loss: 0.2000\n",
            "Epoch 64/100\n",
            "65/65 [==============================] - 0s 119us/step - loss: 0.1999\n",
            "Epoch 65/100\n",
            "65/65 [==============================] - 0s 207us/step - loss: 0.1999\n",
            "Epoch 66/100\n",
            "65/65 [==============================] - 0s 229us/step - loss: 0.1999\n",
            "Epoch 67/100\n",
            "65/65 [==============================] - 0s 259us/step - loss: 0.1998\n",
            "Epoch 68/100\n",
            "65/65 [==============================] - 0s 215us/step - loss: 0.1998\n",
            "Epoch 69/100\n",
            "65/65 [==============================] - 0s 256us/step - loss: 0.1998\n",
            "Epoch 70/100\n",
            "65/65 [==============================] - 0s 254us/step - loss: 0.1998\n",
            "Epoch 71/100\n",
            "65/65 [==============================] - 0s 199us/step - loss: 0.1997\n",
            "Epoch 72/100\n",
            "65/65 [==============================] - 0s 163us/step - loss: 0.1997\n",
            "Epoch 73/100\n",
            "65/65 [==============================] - 0s 92us/step - loss: 0.1997\n",
            "Epoch 74/100\n",
            "65/65 [==============================] - 0s 158us/step - loss: 0.1996\n",
            "Epoch 75/100\n",
            "65/65 [==============================] - 0s 188us/step - loss: 0.1996\n",
            "Epoch 76/100\n",
            "65/65 [==============================] - 0s 154us/step - loss: 0.1996\n",
            "Epoch 77/100\n",
            "65/65 [==============================] - 0s 154us/step - loss: 0.1995\n",
            "Epoch 78/100\n",
            "65/65 [==============================] - 0s 109us/step - loss: 0.1995\n",
            "Epoch 79/100\n",
            "65/65 [==============================] - 0s 175us/step - loss: 0.1995\n",
            "Epoch 80/100\n",
            "65/65 [==============================] - 0s 103us/step - loss: 0.1994\n",
            "Epoch 81/100\n",
            "65/65 [==============================] - 0s 99us/step - loss: 0.1994\n",
            "Epoch 82/100\n",
            "65/65 [==============================] - 0s 133us/step - loss: 0.1994\n",
            "Epoch 83/100\n",
            "65/65 [==============================] - 0s 106us/step - loss: 0.1994\n",
            "Epoch 84/100\n",
            "65/65 [==============================] - 0s 117us/step - loss: 0.1993\n",
            "Epoch 85/100\n",
            "65/65 [==============================] - 0s 116us/step - loss: 0.1993\n",
            "Epoch 86/100\n",
            "65/65 [==============================] - 0s 145us/step - loss: 0.1993\n",
            "Epoch 87/100\n",
            "65/65 [==============================] - 0s 134us/step - loss: 0.1992\n",
            "Epoch 88/100\n",
            "65/65 [==============================] - 0s 145us/step - loss: 0.1992\n",
            "Epoch 89/100\n",
            "65/65 [==============================] - 0s 129us/step - loss: 0.1992\n",
            "Epoch 90/100\n",
            "65/65 [==============================] - 0s 114us/step - loss: 0.1991\n",
            "Epoch 91/100\n",
            "65/65 [==============================] - 0s 118us/step - loss: 0.1991\n",
            "Epoch 92/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.1991\n",
            "Epoch 93/100\n",
            "65/65 [==============================] - 0s 149us/step - loss: 0.1991\n",
            "Epoch 94/100\n",
            "65/65 [==============================] - 0s 194us/step - loss: 0.1990\n",
            "Epoch 95/100\n",
            "65/65 [==============================] - 0s 186us/step - loss: 0.1990\n",
            "Epoch 96/100\n",
            "65/65 [==============================] - 0s 160us/step - loss: 0.1990\n",
            "Epoch 97/100\n",
            "65/65 [==============================] - 0s 165us/step - loss: 0.1989\n",
            "Epoch 98/100\n",
            "65/65 [==============================] - 0s 187us/step - loss: 0.1989\n",
            "Epoch 99/100\n",
            "65/65 [==============================] - 0s 138us/step - loss: 0.1989\n",
            "Epoch 100/100\n",
            "65/65 [==============================] - 0s 153us/step - loss: 0.1988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8a65f7c940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN8AxcsGReIP",
        "colab_type": "code",
        "outputId": "9fff524c-d2ba-492d-cbdb-c2f7a4511078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# Let's test the model\n",
        "y_pred = model.predict(X_test,batch_size=1)\n",
        "\n",
        "y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
        "\n",
        "# Rebuilding test set\n",
        "pred_test_set = []\n",
        "for index in range(0,len(y_pred)):\n",
        "    print(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
        "    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
        "\n",
        "# Reshape pred_test_set\n",
        "pred_test_set = np.array(pred_test_set)\n",
        "pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
        "pred_test_set_inverted = scaler.inverse_transform(pred_test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.14030437 -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102\n",
            "   0.03221136  0.37254192 -0.27349499  0.2195681  -0.25491615  0.02099168\n",
            "   0.30944625]]\n",
            "[[-0.14577715  0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811\n",
            "  -0.62613102  0.03221136  0.37254192 -0.27349499  0.2195681  -0.25491615\n",
            "   0.02099168]]\n",
            "[[-0.08711375 -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491\n",
            "   0.73084811 -0.62613102  0.03221136  0.37254192 -0.27349499  0.2195681\n",
            "  -0.25491615]]\n",
            "[[-0.04487858 -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801\n",
            "  -0.35806491  0.73084811 -0.62613102  0.03221136  0.37254192 -0.27349499\n",
            "   0.2195681 ]]\n",
            "[[-0.15136863  0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965\n",
            "   0.36240801 -0.35806491  0.73084811 -0.62613102  0.03221136  0.37254192\n",
            "  -0.27349499]]\n",
            "[[-0.10093953 -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126\n",
            "  -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102  0.03221136\n",
            "   0.37254192]]\n",
            "[[-0.06772801  0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553\n",
            "   0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102\n",
            "   0.03221136]]\n",
            "[[-0.05030656 -0.03619254  0.30848112 -0.14501146  0.26625648 -0.30329352\n",
            "  -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811\n",
            "  -0.62613102]]\n",
            "[[-0.11161833 -0.89986729 -0.03619254  0.30848112 -0.14501146  0.26625648\n",
            "  -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491\n",
            "   0.73084811]]\n",
            "[[-0.17367652  0.9933647  -0.89986729 -0.03619254  0.30848112 -0.14501146\n",
            "   0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801\n",
            "  -0.35806491]]\n",
            "[[ 0.01879468 -0.36518277  0.9933647  -0.89986729 -0.03619254  0.30848112\n",
            "  -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965\n",
            "   0.36240801]]\n",
            "[[-0.18791564  0.34322596 -0.36518277  0.9933647  -0.89986729 -0.03619254\n",
            "   0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126\n",
            "  -0.28000965]]\n",
            "[[-0.18623787 -0.23102907  0.34322596 -0.36518277  0.9933647  -0.89986729\n",
            "  -0.03619254  0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553\n",
            "   0.34986126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuebhmqvW--o",
        "colab_type": "code",
        "outputId": "1469e7b2-37f3-46ee-8e6a-86e04728a659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Creating a dataframe containing the predictions\n",
        "result_list = []\n",
        "sales_dates = list(df_aggregated[-13:].Monthly)\n",
        "act_sales = list(df_aggregated[-13:].volume)\n",
        "for index in range(0,len(pred_test_set_inverted)):\n",
        "    result_dict = {}\n",
        "    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n",
        "    result_dict['Monthly'] = sales_dates[index]\n",
        "    result_list.append(result_dict)\n",
        "df_result = pd.DataFrame(result_list)\n",
        "df_result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_value</th>\n",
              "      <th>Monthly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74877</td>\n",
              "      <td>2016-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>74490</td>\n",
              "      <td>2016-08-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72301</td>\n",
              "      <td>2016-09-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74698</td>\n",
              "      <td>2016-10-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72452</td>\n",
              "      <td>2016-11-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pred_value    Monthly\n",
              "0       74877 2016-07-01\n",
              "1       74490 2016-08-01\n",
              "2       72301 2016-09-01\n",
              "3       74698 2016-10-01\n",
              "4       72452 2016-11-01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CJM0nvee6i4",
        "colab_type": "code",
        "outputId": "694455a8-b8ec-4f16-a2e1-9d279efa055b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "# We merge the previous sales and predicted sales for vizualisation\n",
        "df_sales_pred = pd.merge(df_aggregated,df_result,on='Monthly',how='left')\n",
        "\n",
        "# Plot actual and predicted\n",
        "plot_data = [\n",
        "    go.Scatter(\n",
        "        x=df_sales_pred['Monthly'],\n",
        "        y=df_sales_pred['volume'],\n",
        "        name='actual'\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        x=df_sales_pred['Monthly'],\n",
        "        y=df_sales_pred['pred_value'],\n",
        "        name='predicted'\n",
        "    )\n",
        "    \n",
        "]\n",
        "plot_layout = go.Layout(\n",
        "        title='Sales Prediction'\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "pyoff.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"2bbb7ef9-63dd-4b4a-8709-001c0b1466ff\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"2bbb7ef9-63dd-4b4a-8709-001c0b1466ff\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '2bbb7ef9-63dd-4b4a-8709-001c0b1466ff',\n",
              "                        [{\"name\": \"actual\", \"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [75189, 68422, 74926, 72102, 75304, 72838, 75197, 76231, 73055, 73806, 72549, 75068, 76246, 68859, 76355, 73853, 74843, 72383, 75673, 75149, 73620, 75790, 73629, 76471, 73869, 70311, 76015, 73257, 76089, 73380, 76220, 75462, 72690, 75901, 72141, 74354, 76417, 68546, 76048, 72133, 75125, 72899, 75643, 76052, 74163, 75972, 73685, 75559, 76087, 67637, 75765, 73044, 75990, 74231, 75841, 75812, 73284, 76170, 72918, 76032, 74679, 68057, 75422, 72228, 74843, 73277, 75681, 75694, 73420, 75079, 72651, 75578, 75684, 70333, 76230, 73101, 75944, 73462, 76201, 75860, 73185, 75231, 73868, 76264, 75803, 68183, 76256, 73068, 75752, 73676, 69874]}, {\"name\": \"predicted\", \"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 74877.0, 74490.0, 72301.0, 74698.0, 72452.0, 75266.0, 75080.0, 67605.0, 75169.0, 71467.0, 75746.0, 71957.0, 68169.0]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Sales Prediction\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2bbb7ef9-63dd-4b4a-8709-001c0b1466ff');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSPqwcW5x9x2",
        "colab_type": "text"
      },
      "source": [
        "## Part 4 : Multilayer Perceptron training and testing\n",
        "\n",
        "In this part, we are going to see the results using a multilayer perceptron. This part will be useful to compare with LSTM neural network and see if those where really useful. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjH3kwIN0Vvj",
        "colab_type": "code",
        "outputId": "a6abd918-7c9c-4902-9e48-eb4b33156020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# # Creating the neural net\n",
        "model = Sequential()\n",
        "\n",
        "# Creating the multilayer perceptron. \n",
        "# Each '.add' add a new layer to the neural net\n",
        "model.add(Dense(units=1, activation='sigmoid')) # Input layer\n",
        "model.add(Dense(units=1, activation='relu')) # Hidden layer\n",
        "model.add(Dense(units=1, activation='sigmoid')) # Output layer\n",
        "\n",
        "# If overfitting happens, we can use dropout\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# Same loss function and same optimizer as the RNN ones'\n",
        "model.compile(loss='mean_squared_error', optimizer='SGD')\n",
        "model.fit(train_set_scaled, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "65/65 [==============================] - 0s 806us/step - loss: 0.4327\n",
            "Epoch 2/100\n",
            "65/65 [==============================] - 0s 112us/step - loss: 0.4317\n",
            "Epoch 3/100\n",
            "65/65 [==============================] - 0s 85us/step - loss: 0.4304\n",
            "Epoch 4/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.4295\n",
            "Epoch 5/100\n",
            "65/65 [==============================] - 0s 101us/step - loss: 0.4272\n",
            "Epoch 6/100\n",
            "65/65 [==============================] - 0s 100us/step - loss: 0.4266\n",
            "Epoch 7/100\n",
            "65/65 [==============================] - 0s 108us/step - loss: 0.4259\n",
            "Epoch 8/100\n",
            "65/65 [==============================] - 0s 92us/step - loss: 0.4243\n",
            "Epoch 9/100\n",
            "65/65 [==============================] - 0s 84us/step - loss: 0.4229\n",
            "Epoch 10/100\n",
            "65/65 [==============================] - 0s 88us/step - loss: 0.4216\n",
            "Epoch 11/100\n",
            "65/65 [==============================] - 0s 83us/step - loss: 0.4195\n",
            "Epoch 12/100\n",
            "65/65 [==============================] - 0s 91us/step - loss: 0.4182\n",
            "Epoch 13/100\n",
            "65/65 [==============================] - 0s 114us/step - loss: 0.4163\n",
            "Epoch 14/100\n",
            "65/65 [==============================] - 0s 90us/step - loss: 0.4155\n",
            "Epoch 15/100\n",
            "65/65 [==============================] - 0s 170us/step - loss: 0.4148\n",
            "Epoch 16/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.4129\n",
            "Epoch 17/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.4117\n",
            "Epoch 18/100\n",
            "65/65 [==============================] - 0s 105us/step - loss: 0.4105\n",
            "Epoch 19/100\n",
            "65/65 [==============================] - 0s 98us/step - loss: 0.4087\n",
            "Epoch 20/100\n",
            "65/65 [==============================] - 0s 121us/step - loss: 0.4068\n",
            "Epoch 21/100\n",
            "65/65 [==============================] - 0s 100us/step - loss: 0.4050\n",
            "Epoch 22/100\n",
            "65/65 [==============================] - 0s 149us/step - loss: 0.4030\n",
            "Epoch 23/100\n",
            "65/65 [==============================] - 0s 102us/step - loss: 0.4011\n",
            "Epoch 24/100\n",
            "65/65 [==============================] - 0s 113us/step - loss: 0.3998\n",
            "Epoch 25/100\n",
            "65/65 [==============================] - 0s 150us/step - loss: 0.3987\n",
            "Epoch 26/100\n",
            "65/65 [==============================] - 0s 129us/step - loss: 0.3974\n",
            "Epoch 27/100\n",
            "65/65 [==============================] - 0s 129us/step - loss: 0.3963\n",
            "Epoch 28/100\n",
            "65/65 [==============================] - 0s 102us/step - loss: 0.3958\n",
            "Epoch 29/100\n",
            "65/65 [==============================] - 0s 146us/step - loss: 0.3946\n",
            "Epoch 30/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.3927\n",
            "Epoch 31/100\n",
            "65/65 [==============================] - 0s 125us/step - loss: 0.3917\n",
            "Epoch 32/100\n",
            "65/65 [==============================] - 0s 126us/step - loss: 0.3906\n",
            "Epoch 33/100\n",
            "65/65 [==============================] - 0s 144us/step - loss: 0.3901\n",
            "Epoch 34/100\n",
            "65/65 [==============================] - 0s 132us/step - loss: 0.3884\n",
            "Epoch 35/100\n",
            "65/65 [==============================] - 0s 88us/step - loss: 0.3867\n",
            "Epoch 36/100\n",
            "65/65 [==============================] - 0s 91us/step - loss: 0.3856\n",
            "Epoch 37/100\n",
            "65/65 [==============================] - 0s 175us/step - loss: 0.3846\n",
            "Epoch 38/100\n",
            "65/65 [==============================] - 0s 90us/step - loss: 0.3830\n",
            "Epoch 39/100\n",
            "65/65 [==============================] - 0s 145us/step - loss: 0.3819\n",
            "Epoch 40/100\n",
            "65/65 [==============================] - 0s 104us/step - loss: 0.3805\n",
            "Epoch 41/100\n",
            "65/65 [==============================] - 0s 91us/step - loss: 0.3788\n",
            "Epoch 42/100\n",
            "65/65 [==============================] - 0s 84us/step - loss: 0.3782\n",
            "Epoch 43/100\n",
            "65/65 [==============================] - 0s 135us/step - loss: 0.3773\n",
            "Epoch 44/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.3761\n",
            "Epoch 45/100\n",
            "65/65 [==============================] - 0s 83us/step - loss: 0.3751\n",
            "Epoch 46/100\n",
            "65/65 [==============================] - 0s 90us/step - loss: 0.3739\n",
            "Epoch 47/100\n",
            "65/65 [==============================] - 0s 91us/step - loss: 0.3722\n",
            "Epoch 48/100\n",
            "65/65 [==============================] - 0s 95us/step - loss: 0.3706\n",
            "Epoch 49/100\n",
            "65/65 [==============================] - 0s 118us/step - loss: 0.3684\n",
            "Epoch 50/100\n",
            "65/65 [==============================] - 0s 116us/step - loss: 0.3670\n",
            "Epoch 51/100\n",
            "65/65 [==============================] - 0s 107us/step - loss: 0.3655\n",
            "Epoch 52/100\n",
            "65/65 [==============================] - 0s 106us/step - loss: 0.3645\n",
            "Epoch 53/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.3626\n",
            "Epoch 54/100\n",
            "65/65 [==============================] - 0s 105us/step - loss: 0.3614\n",
            "Epoch 55/100\n",
            "65/65 [==============================] - 0s 100us/step - loss: 0.3600\n",
            "Epoch 56/100\n",
            "65/65 [==============================] - 0s 111us/step - loss: 0.3590\n",
            "Epoch 57/100\n",
            "65/65 [==============================] - 0s 80us/step - loss: 0.3576\n",
            "Epoch 58/100\n",
            "65/65 [==============================] - 0s 109us/step - loss: 0.3567\n",
            "Epoch 59/100\n",
            "65/65 [==============================] - 0s 103us/step - loss: 0.3554\n",
            "Epoch 60/100\n",
            "65/65 [==============================] - 0s 83us/step - loss: 0.3540\n",
            "Epoch 61/100\n",
            "65/65 [==============================] - 0s 103us/step - loss: 0.3531\n",
            "Epoch 62/100\n",
            "65/65 [==============================] - 0s 92us/step - loss: 0.3520\n",
            "Epoch 63/100\n",
            "65/65 [==============================] - 0s 104us/step - loss: 0.3501\n",
            "Epoch 64/100\n",
            "65/65 [==============================] - 0s 108us/step - loss: 0.3488\n",
            "Epoch 65/100\n",
            "65/65 [==============================] - 0s 104us/step - loss: 0.3487\n",
            "Epoch 66/100\n",
            "65/65 [==============================] - 0s 99us/step - loss: 0.3480\n",
            "Epoch 67/100\n",
            "65/65 [==============================] - 0s 90us/step - loss: 0.3472\n",
            "Epoch 68/100\n",
            "65/65 [==============================] - 0s 112us/step - loss: 0.3459\n",
            "Epoch 69/100\n",
            "65/65 [==============================] - 0s 100us/step - loss: 0.3448\n",
            "Epoch 70/100\n",
            "65/65 [==============================] - 0s 106us/step - loss: 0.3440\n",
            "Epoch 71/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.3437\n",
            "Epoch 72/100\n",
            "65/65 [==============================] - 0s 98us/step - loss: 0.3430\n",
            "Epoch 73/100\n",
            "65/65 [==============================] - 0s 90us/step - loss: 0.3418\n",
            "Epoch 74/100\n",
            "65/65 [==============================] - 0s 101us/step - loss: 0.3409\n",
            "Epoch 75/100\n",
            "65/65 [==============================] - 0s 105us/step - loss: 0.3406\n",
            "Epoch 76/100\n",
            "65/65 [==============================] - 0s 106us/step - loss: 0.3399\n",
            "Epoch 77/100\n",
            "65/65 [==============================] - 0s 106us/step - loss: 0.3387\n",
            "Epoch 78/100\n",
            "65/65 [==============================] - 0s 104us/step - loss: 0.3379\n",
            "Epoch 79/100\n",
            "65/65 [==============================] - 0s 102us/step - loss: 0.3372\n",
            "Epoch 80/100\n",
            "65/65 [==============================] - 0s 82us/step - loss: 0.3361\n",
            "Epoch 81/100\n",
            "65/65 [==============================] - 0s 97us/step - loss: 0.3359\n",
            "Epoch 82/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.3347\n",
            "Epoch 83/100\n",
            "65/65 [==============================] - 0s 78us/step - loss: 0.3336\n",
            "Epoch 84/100\n",
            "65/65 [==============================] - 0s 80us/step - loss: 0.3324\n",
            "Epoch 85/100\n",
            "65/65 [==============================] - 0s 98us/step - loss: 0.3317\n",
            "Epoch 86/100\n",
            "65/65 [==============================] - 0s 104us/step - loss: 0.3308\n",
            "Epoch 87/100\n",
            "65/65 [==============================] - 0s 123us/step - loss: 0.3298\n",
            "Epoch 88/100\n",
            "65/65 [==============================] - 0s 97us/step - loss: 0.3288\n",
            "Epoch 89/100\n",
            "65/65 [==============================] - 0s 95us/step - loss: 0.3277\n",
            "Epoch 90/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.3261\n",
            "Epoch 91/100\n",
            "65/65 [==============================] - 0s 103us/step - loss: 0.3259\n",
            "Epoch 92/100\n",
            "65/65 [==============================] - 0s 108us/step - loss: 0.3252\n",
            "Epoch 93/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.3242\n",
            "Epoch 94/100\n",
            "65/65 [==============================] - 0s 93us/step - loss: 0.3236\n",
            "Epoch 95/100\n",
            "65/65 [==============================] - 0s 101us/step - loss: 0.3233\n",
            "Epoch 96/100\n",
            "65/65 [==============================] - 0s 115us/step - loss: 0.3226\n",
            "Epoch 97/100\n",
            "65/65 [==============================] - 0s 121us/step - loss: 0.3220\n",
            "Epoch 98/100\n",
            "65/65 [==============================] - 0s 151us/step - loss: 0.3214\n",
            "Epoch 99/100\n",
            "65/65 [==============================] - 0s 137us/step - loss: 0.3206\n",
            "Epoch 100/100\n",
            "65/65 [==============================] - 0s 92us/step - loss: 0.3194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8a6ecfb208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FPeOnQ0CbWb",
        "colab_type": "code",
        "outputId": "07899965-fa12-4ae1-fcc0-eaea90009d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# Let's test the model\n",
        "y_pred = model.predict(test_set_scaled, batch_size=1)\n",
        "\n",
        "y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
        "\n",
        "# Rebuilding test set\n",
        "pred_test_set = []\n",
        "for index in range(0,len(y_pred)):\n",
        "    print(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
        "    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
        "\n",
        "# Reshape pred_test_set\n",
        "pred_test_set = np.array(pred_test_set)\n",
        "pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
        "pred_test_set_inverted = scaler.inverse_transform(pred_test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.3629193  -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102\n",
            "   0.03221136  0.37254192 -0.27349499  0.2195681  -0.25491615  0.02099168\n",
            "   0.30944625]]\n",
            "[[ 0.3629193   0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811\n",
            "  -0.62613102  0.03221136  0.37254192 -0.27349499  0.2195681  -0.25491615\n",
            "   0.02099168]]\n",
            "[[ 0.3629193  -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491\n",
            "   0.73084811 -0.62613102  0.03221136  0.37254192 -0.27349499  0.2195681\n",
            "  -0.25491615]]\n",
            "[[ 0.3629193  -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801\n",
            "  -0.35806491  0.73084811 -0.62613102  0.03221136  0.37254192 -0.27349499\n",
            "   0.2195681 ]]\n",
            "[[ 0.3629193   0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965\n",
            "   0.36240801 -0.35806491  0.73084811 -0.62613102  0.03221136  0.37254192\n",
            "  -0.27349499]]\n",
            "[[ 0.3629193  -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126\n",
            "  -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102  0.03221136\n",
            "   0.37254192]]\n",
            "[[ 0.3629193   0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553\n",
            "   0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811 -0.62613102\n",
            "   0.03221136]]\n",
            "[[ 0.3629193  -0.03619254  0.30848112 -0.14501146  0.26625648 -0.30329352\n",
            "  -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491  0.73084811\n",
            "  -0.62613102]]\n",
            "[[ 0.3629193  -0.89986729 -0.03619254  0.30848112 -0.14501146  0.26625648\n",
            "  -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801 -0.35806491\n",
            "   0.73084811]]\n",
            "[[ 0.3629193   0.9933647  -0.89986729 -0.03619254  0.30848112 -0.14501146\n",
            "   0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965  0.36240801\n",
            "  -0.35806491]]\n",
            "[[ 0.3629193  -0.36518277  0.9933647  -0.89986729 -0.03619254  0.30848112\n",
            "  -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126 -0.28000965\n",
            "   0.36240801]]\n",
            "[[ 0.3629193   0.34322596 -0.36518277  0.9933647  -0.89986729 -0.03619254\n",
            "   0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553  0.34986126\n",
            "  -0.28000965]]\n",
            "[[ 0.3629193  -0.23102907  0.34322596 -0.36518277  0.9933647  -0.89986729\n",
            "  -0.03619254  0.30848112 -0.14501146  0.26625648 -0.30329352 -0.02171553\n",
            "   0.34986126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTt90ojZCiwg",
        "colab_type": "code",
        "outputId": "fd0e9fd6-d68a-43d4-f098-b18ad217c5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Creating a dataframe containing the predictions\n",
        "result_list = []\n",
        "sales_dates = list(df_aggregated[-13:].Monthly)\n",
        "act_sales = list(df_aggregated[-13:].volume)\n",
        "for index in range(0,len(pred_test_set_inverted)):\n",
        "    result_dict = {}\n",
        "    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n",
        "    result_dict['Monthly'] = sales_dates[index]\n",
        "    result_list.append(result_dict)\n",
        "df_result = pd.DataFrame(result_list)\n",
        "df_result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_value</th>\n",
              "      <th>Monthly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79048</td>\n",
              "      <td>2016-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>78707</td>\n",
              "      <td>2016-08-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>76032</td>\n",
              "      <td>2016-09-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78078</td>\n",
              "      <td>2016-10-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76715</td>\n",
              "      <td>2016-11-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pred_value    Monthly\n",
              "0       79048 2016-07-01\n",
              "1       78707 2016-08-01\n",
              "2       76032 2016-09-01\n",
              "3       78078 2016-10-01\n",
              "4       76715 2016-11-01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypO01zhdCmlz",
        "colab_type": "code",
        "outputId": "82ec2eb9-72f2-44f6-a778-158ca400898c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "# We merge the previous sales and predicted sales for vizualisation\n",
        "df_sales_pred = pd.merge(df_aggregated,df_result,on='Monthly',how='left')\n",
        "\n",
        "# Plot actual and predicted\n",
        "plot_data = [\n",
        "    go.Scatter(\n",
        "        x=df_sales_pred['Monthly'],\n",
        "        y=df_sales_pred['volume'],\n",
        "        name='actual'\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        x=df_sales_pred['Monthly'],\n",
        "        y=df_sales_pred['pred_value'],\n",
        "        name='predicted'\n",
        "    )\n",
        "    \n",
        "]\n",
        "plot_layout = go.Layout(\n",
        "        title='Sales Prediction'\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "pyoff.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7d8c692f-0bcc-431e-a03f-9a8873943445\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7d8c692f-0bcc-431e-a03f-9a8873943445\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7d8c692f-0bcc-431e-a03f-9a8873943445',\n",
              "                        [{\"name\": \"actual\", \"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [75189, 68422, 74926, 72102, 75304, 72838, 75197, 76231, 73055, 73806, 72549, 75068, 76246, 68859, 76355, 73853, 74843, 72383, 75673, 75149, 73620, 75790, 73629, 76471, 73869, 70311, 76015, 73257, 76089, 73380, 76220, 75462, 72690, 75901, 72141, 74354, 76417, 68546, 76048, 72133, 75125, 72899, 75643, 76052, 74163, 75972, 73685, 75559, 76087, 67637, 75765, 73044, 75990, 74231, 75841, 75812, 73284, 76170, 72918, 76032, 74679, 68057, 75422, 72228, 74843, 73277, 75681, 75694, 73420, 75079, 72651, 75578, 75684, 70333, 76230, 73101, 75944, 73462, 76201, 75860, 73185, 75231, 73868, 76264, 75803, 68183, 76256, 73068, 75752, 73676, 69874]}, {\"name\": \"predicted\", \"type\": \"scatter\", \"x\": [\"2010-01-01T00:00:00\", \"2010-02-01T00:00:00\", \"2010-03-01T00:00:00\", \"2010-04-01T00:00:00\", \"2010-05-01T00:00:00\", \"2010-06-01T00:00:00\", \"2010-07-01T00:00:00\", \"2010-08-01T00:00:00\", \"2010-09-01T00:00:00\", \"2010-10-01T00:00:00\", \"2010-11-01T00:00:00\", \"2010-12-01T00:00:00\", \"2011-01-01T00:00:00\", \"2011-02-01T00:00:00\", \"2011-03-01T00:00:00\", \"2011-04-01T00:00:00\", \"2011-05-01T00:00:00\", \"2011-06-01T00:00:00\", \"2011-07-01T00:00:00\", \"2011-08-01T00:00:00\", \"2011-09-01T00:00:00\", \"2011-10-01T00:00:00\", \"2011-11-01T00:00:00\", \"2011-12-01T00:00:00\", \"2012-01-01T00:00:00\", \"2012-02-01T00:00:00\", \"2012-03-01T00:00:00\", \"2012-04-01T00:00:00\", \"2012-05-01T00:00:00\", \"2012-06-01T00:00:00\", \"2012-07-01T00:00:00\", \"2012-08-01T00:00:00\", \"2012-09-01T00:00:00\", \"2012-10-01T00:00:00\", \"2012-11-01T00:00:00\", \"2012-12-01T00:00:00\", \"2013-01-01T00:00:00\", \"2013-02-01T00:00:00\", \"2013-03-01T00:00:00\", \"2013-04-01T00:00:00\", \"2013-05-01T00:00:00\", \"2013-06-01T00:00:00\", \"2013-07-01T00:00:00\", \"2013-08-01T00:00:00\", \"2013-09-01T00:00:00\", \"2013-10-01T00:00:00\", \"2013-11-01T00:00:00\", \"2013-12-01T00:00:00\", \"2014-01-01T00:00:00\", \"2014-02-01T00:00:00\", \"2014-03-01T00:00:00\", \"2014-04-01T00:00:00\", \"2014-05-01T00:00:00\", \"2014-06-01T00:00:00\", \"2014-07-01T00:00:00\", \"2014-08-01T00:00:00\", \"2014-09-01T00:00:00\", \"2014-10-01T00:00:00\", \"2014-11-01T00:00:00\", \"2014-12-01T00:00:00\", \"2015-01-01T00:00:00\", \"2015-02-01T00:00:00\", \"2015-03-01T00:00:00\", \"2015-04-01T00:00:00\", \"2015-05-01T00:00:00\", \"2015-06-01T00:00:00\", \"2015-07-01T00:00:00\", \"2015-08-01T00:00:00\", \"2015-09-01T00:00:00\", \"2015-10-01T00:00:00\", \"2015-11-01T00:00:00\", \"2015-12-01T00:00:00\", \"2016-01-01T00:00:00\", \"2016-02-01T00:00:00\", \"2016-03-01T00:00:00\", \"2016-04-01T00:00:00\", \"2016-05-01T00:00:00\", \"2016-06-01T00:00:00\", \"2016-07-01T00:00:00\", \"2016-08-01T00:00:00\", \"2016-09-01T00:00:00\", \"2016-10-01T00:00:00\", \"2016-11-01T00:00:00\", \"2016-12-01T00:00:00\", \"2017-01-01T00:00:00\", \"2017-02-01T00:00:00\", \"2017-03-01T00:00:00\", \"2017-04-01T00:00:00\", \"2017-05-01T00:00:00\", \"2017-06-01T00:00:00\", \"2017-07-01T00:00:00\"], \"y\": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 79048.0, 78707.0, 76032.0, 78078.0, 76715.0, 79111.0, 78650.0, 71030.0, 79103.0, 75915.0, 78599.0, 76523.0, 72721.0]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Sales Prediction\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7d8c692f-0bcc-431e-a03f-9a8873943445');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rZDKlJRNZUW",
        "colab_type": "text"
      },
      "source": [
        "As you can see above, the multilayer perceptron is a bit optimistic. However, when we compare to the RNN with batch_size 32, we could add the two output - perceptron and RNN_32 - then divide them by 2 and see if the results are even better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUAEq4jLGlY",
        "colab_type": "text"
      },
      "source": [
        "## Part 5 : Results\n",
        "\n",
        "As the graphs illustrate, **the RNN with a batch_size of 32 gave the best results** - that can be explained because a higher batch gives more homogeneity.\n",
        "Multilayers perceptron gave also a good resultats but with a bit of too much optimism.\n",
        "**RNN with a batch size of 1 gave the worst results**, probably due to overfitting - as the loss being the lowest of 3. One could underline the fact we didn't use dropout on RNN with batch_size of 1, maybe it would have landed good relsults.\n",
        "Also, it could be interesting to add the outputs of RNN + multilayers perceptron and divide them by 2 to see the results - as RNN is a bit unoptimistic and perceptron a bit too much."
      ]
    }
  ]
}